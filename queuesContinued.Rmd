---
title: "Modeling, Simulating, and Measuring the Performance of Queues"
author: "Anthony Hung"
date: "2019-03-01"
output: pdf_document
header-includes:
     - \usepackage{outlines}
     - \usepackage{enumitem}
     - \usepackage{tikz}
     - \usetikzlibrary{arrows}
     - \usepackage{tabularx}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(12)
```

#Prerequisites

This vignette continues from concepts covered in the vignette: "Introduction to Queueing Theory and Queueing Models".

#Introduction

In addition to simply being able to represent waiting lines mathematically, queueing theory allows for the evaluation of the behavior and performance of queues. Being able to measure the performance of queues also allows us to determine the effects of altering components of the queue on performance.

#Simulating a M/M/1 queue

In simulating a M/M/1 queue, we want to keep track of three values of the queue over time. 

\begin{outline}[enumerate]
   \1 Arrival times of customers
   \1 Departure times of customers
   \1 The number of customers in the system at every moment of arrivals or departures
\end{outline}

In simulating the queue behavior, we can take advantage of the superposition property of combined independent Poisson processes. Since arrivals and departures are indepdendent, the number of events in the combined process can be represented as a Poisson process with parameter $\lambda_{sum} = \lambda + \mu$. The probability of an event in this combined process being an arrival is $\frac{\lambda}{(\lambda+\mu)}$, and the probabilty of it being a departure is $\frac{\mu}{(\lambda+\mu)}$.

The function "simulate_MM1" simulates the number of customers in a M/M/1 queue over time given values for lambda, mu, and $N_0$ from $T_0$ to $T_{max}$. It also keeps track of when events (arrivals or departures) occur during the time periods and what type of event occurs at each of those moments.

```{r simulateQueue}
lambda <- 4
mu <- 5

simulate_MM1 <- function(lambda=lambda, mu=mu, N0=0, Tmax=1000){
  #Initialize vectors to store each of the values of interest throughout the simulation
  events <- 0 #stores the type of event (1 for arrival, -1 for departure)
  Times <- 0 #times of events
  customers <- N0 #number of customers at each time in Times
  
  while(tail(Times,1) < Tmax){ #keep simulating until you have an event at a time greater than Tmax
    
    if(tail(customers,1)==0){ #separate behavior occurs if system currently has 0 customers
      tau <- rexp(1, rate=lambda) #interarrival intervals are exponentially distributed
      event <- 1 #only an arrival can occur if thre are 0 customers
      
    } else {
      tau <- rexp(1, rate=lambda+mu) #inter-event intervals are exponentially distributed
      if(runif(1,0,1) < lambda/(lambda+mu)){ #if runif is less than P(event = arrival)...
        event <- 1 #call the event an arrival
      } else{ 
        event <- -1 #otherwise, call the event a departure
      }
    }
    
    #now that we have simulatd one event, we need to do some accounting
    customers <- c(customers, tail(customers,1)+event)
    Times <- c(Times, tail(Times,1)+tau)
    events <- c(events, event)
  }
  
  #we need to toss out the information from the last event (it occured after Tmax)
  events <- head(events, -1)
  Times <- head(Times, -1)
  customers <- head(customers, -1)
  
  return(list(events,Times,customers))
}
```

After simulating the number of customers in the queue over one run of the simulation, we can plot it.

```{r}
sim <- simulate_MM1(lambda = 4, mu=5, N0=0, Tmax=1000)
plot(x=sim[[2]], y=sim[[3]], xlab="time", ylab="Number of customers")#number of customers vs time
```

Notice that if $\lambda > \mu$, the customer number explodes and will never reach a steady state.

```{r}
sim2 <- simulate_MM1(lambda = 6, mu=5, N0=0, Tmax=1000)
plot(x=sim2[[2]], y=sim2[[3]], xlab="time", ylab="Number of customers")#number of customers vs time
```

#Measuring the performance of queues

There are several formal quantities used to measure the performance of a queueing system (with c servers).

\begin{outline}[enumerate]
   \1 $\pi_j$ := The stationary probability that there are j customers in the system
   \1 $a$ := Offered load. The mean number of requests per service time.
   \1 $\rho$ := Traffic intensity. Offered load per server ($a/c$).
   \1 $a'$ := Carried load. Mean number of busy servers.
   \1 $\rho'$ := Server occupancy. Carried load per server ($a'/c$).
   \1 $W_s$ := Mean length of time between a customer's arrival and the customer's departure from the system.
   \1 $W_q$ := Mean length of time between a customer's arrival and when the customer's service starts.
   \1 $L_s$ := Mean number of customers in the system, including those in the buffer and at servers.
   \1 $L_q$ := Mean number of customers waiting in the buffer.
\end{outline}

We can analyze the performance of a M/M/1 queue.

\underline{$\pi_j$}

For the M/M/1 queue, we previously calculated the stationary probabilities:

$$\pi_n = \frac{\lambda^n}{\mu^n}\frac{1}{1+\sum\limits_{a=1}^{\infty} \frac{\lambda ^a}{\mu ^a}}$$

\underline{$a$, $\rho$}

The offered load of a server is given by the ratio of the arrival rate to the departure rate (i.e. the mean number of arrivals that occur during the mean service time).  Traffic intensity is the offered load per server.

$$a = \frac{\lambda}{\mu}$$
$$\rho = \frac{a}{c} = \frac{\frac{\lambda}{\mu}}{1} = \frac{\lambda}{\mu}$$

\underline{$a'$}

The carried load can be thought of as the mean number of customers that complete service per mean service time $\frac{1}{\mu}$. Intuitively, for a queue like the M/M/1 queue with only 1 server, this will equal 1. $a'$ and $a$ are both dimensionless and expressed in "erlang" units. If the queueing system does not ever block customers (i.e. all customers that arrive to the queue will eventually be served and none are turned away due to a buffer size limits) then $a=a'$ and $\rho = \rho'$. If customers are blocked, then $a>a'$ and $\rho >\rho '$

$$a' = \sum\limits^{s-1}_{j=0} jp_j + s \sum\limits^{\infty}_{j=s}p_j = 0+1 = 1$$

$$\rho' = \frac{a'}{c} = \frac{1}{1} = 1$$

\underline{A brief interlude: Little's Law}

Little's law states that the long-term average of the number of customers in any queue at stationarity is equal to the long-term average arrival rate Î» multiplied by the average time that a customer spends in the system. Expressed algebraically using our defined variables:

$$L_s = \lambda W_s$$

Little's law also holds for the number of customers waiting in the queue buffer:

$$L_q = \lambda W_q$$

Little's Law was originally presented by John Little in 1954 without proof, but multiple proofs of the relationship have been published since (https://pubsonline.informs.org/doi/abs/10.1287/opre.20.6.1115). We can make use of the relationships stated in Little's Law in working with the last four performance measures.



In addition to knowing the equations to compute these performance metrics for the M/M/1 queue, we can also compute them for the data we simulated above.

#Multiple servers: the M/M/c queue

